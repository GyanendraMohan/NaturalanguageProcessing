{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edaf1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827f41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am learning Natural Language Processing. Natural Language Processing is interesting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed3abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5a5433",
   "metadata": {},
   "source": [
    "Convert a collection of text documents to a matrix of token counts.               \n",
    "CountVectorizer doesn't have normalization, it just counts the number of times a word appears in the text. It does not take into account the length of the document or the frequency of the word in the corpus. This can lead to issues when comparing documents of different lengths or when comparing words that appear frequently in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4303ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'am': 0, 'learning': 4, 'natural': 5, 'language': 3, 'processing': 6, 'is': 2, 'interesting': 1}\n",
      "[[1 1 1 2 1 2 2]]\n"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer()\n",
    "vector.fit([text])\n",
    "matrix = vector.transform([text]).toarray() # convert the text into a matrix of token counts\n",
    "print(vector.vocabulary_)   # get the vocabulary of the text\n",
    "print(matrix)   # get the matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22aa0995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'natural', 'language', 'processing']\n"
     ]
    }
   ],
   "source": [
    "str = \"i love natural language processing\"\n",
    "tokens =str.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3176e0ae",
   "metadata": {},
   "source": [
    "# Punctuation\n",
    "Punctuation may be important for some downstream tasks like sentiment analysis.\n",
    "So tokenizing punctuation may be important for some tasks.\n",
    "CountVectorizer by default removes punctuation, but we can change this behavior by setting the `token_pattern` parameter to include punctuation. For example, we can set `token_pattern=r'\\b\\w+\\b|[^\\w\\s]'` to include both words and punctuation as tokens. This will allow us to capture the punctuation in the text, which may be important for certain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aba9426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': 4, ',': 0, 'how': 5, 'are': 2, 'you': 6, 'doing': 3, '?': 1}\n",
      "[[1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "txt = \"hi, how are you doing?\"\n",
    "word_vectorizer = CountVectorizer(analyzer='word', token_pattern=r'\\b\\w+\\b|[^\\w\\s]')\n",
    "word_vectorizer.fit([txt])\n",
    "word_matrix = word_vectorizer.transform([txt]).toarray()\n",
    "print(word_vectorizer.vocabulary_)\n",
    "print(word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1703d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning': 2, 'natural': 3, 'language': 1, 'processing': 4, 'interesting': 0}\n",
      "[[1 2 1 2 2]]\n"
     ]
    }
   ],
   "source": [
    "# Stopwords in count vectorizer\n",
    "token = CountVectorizer(stop_words='english')\n",
    "token.fit([text])\n",
    "token_matrix = token.transform([text]).toarray()\n",
    "print(token.vocabulary_)\n",
    "print(token_matrix) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
