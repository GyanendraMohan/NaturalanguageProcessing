{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d753021a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/gyanendramohanpatel/De\n",
            "[nltk_data]     sktop/NaturalanguageProcessing/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /Users/gyanendramohanpate\n",
            "[nltk_data]     l/Desktop/NaturalanguageProcessing/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/gyanendramohanpatel/\n",
            "[nltk_data]     Desktop/NaturalanguageProcessing/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /Users/gyanendramohanpatel/\n",
            "[nltk_data]     Desktop/NaturalanguageProcessing/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import os\n",
        "PROJECT_ROOT = os.path.abspath(\"..\")\n",
        "NLTK_DATA_PATH = os.path.join(PROJECT_ROOT, \"nltk_data\")\n",
        "if NLTK_DATA_PATH not in nltk.data.path:\n",
        "    nltk.data.path.append(NLTK_DATA_PATH)\n",
        "resources = ['punkt', 'stopwords', 'wordnet', 'omw-1.4']\n",
        "for res in resources:\n",
        "    try:\n",
        "        nltk.data.find(res)\n",
        "    except LookupError:\n",
        "        nltk.download(res, download_dir=NLTK_DATA_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "38b554e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "24f5069d",
      "metadata": {},
      "outputs": [],
      "source": [
        "text = input(\"Enter a texts: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fe68f3ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hi this is the lab1 of nlp here we go welcome to lab']\n"
          ]
        }
      ],
      "source": [
        "# Sentence Tokenization\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "dd6dc9a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Tokenization\n",
            "['hi', 'this', 'is', 'the', 'lab1', 'of', 'nlp', 'here', 'we', 'go', 'welcome', 'to', 'lab']\n"
          ]
        }
      ],
      "source": [
        "#word tokenization\n",
        "words = word_tokenize(text)\n",
        "print(\"Word Tokenization\")\n",
        "print(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c1903a26",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regex Tokenization\n",
            "['hi', 'this', 'is', 'the', 'lab1', 'of', 'nlp', 'here', 'we', 'go', 'welcome', 'to', 'lab']\n"
          ]
        }
      ],
      "source": [
        "#Regular Expression Tokenization\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "processed_word = tokenizer.tokenize(text.lower())\n",
        "print(\"Regex Tokenization\")\n",
        "print(processed_word)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fb246f00",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop word removal\n",
            "['hi', 'lab1', 'nlp', 'go', 'welcome', 'lab']\n"
          ]
        }
      ],
      "source": [
        "# Remove stopwords\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "print(\"Stop word removal\")\n",
        "print(filtered_words)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "314cc467",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "5. Synsets:\n",
            "welcome.n.01 : the state of being welcome\n",
            "welcome.n.02 : a greeting or reception\n",
            "welcome.v.01 : accept gladly\n",
            "welcome.v.02 : bid welcome to; greet upon arrival\n",
            "welcome.v.03 : receive someone, as into one's house\n",
            "welcome.a.01 : giving pleasure or satisfaction or received with pleasure or freely granted\n"
          ]
        }
      ],
      "source": [
        "#Synset\n",
        "word1 = input(\"\\nEnter a word to view synsets: \")\n",
        "synsets = wordnet.synsets(word1)\n",
        "\n",
        "print(\"\\n5. Synsets:\")\n",
        "for syn in synsets:\n",
        "    print(syn.name(), \":\", syn.definition())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f1389158",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'welcome', 'receive'}\n"
          ]
        }
      ],
      "source": [
        "#Lemmas\n",
        "lemmas = set()\n",
        "for syn in synsets:\n",
        "    for lemma in syn.lemmas():\n",
        "        lemmas.add(lemma.name())\n",
        "print(lemmas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a6764339",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "7. Semantic Similarity between 'welcome' and 'NLP': 0.07142857142857142\n"
          ]
        }
      ],
      "source": [
        "#Semantic similarity\n",
        "word2 = input(\"Enter a word2 for similarity: \")\n",
        "syn1 = wordnet.synsets(word1)\n",
        "syn2 = wordnet.synsets(word2)\n",
        "\n",
        "\n",
        "if syn1 and syn2:\n",
        "    similarity = syn1[0].path_similarity(syn2[0])\n",
        "    print(f\"\\n7. Semantic Similarity between '{word1}' and '{word2}': {similarity}\")\n",
        "else:\n",
        "    print(\"\\n7. Similarity cannot be calculated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8057053d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 Word Collocations:\n",
            "[('go', 'welcome'), ('hi', 'lab1'), ('lab1', 'nlp'), ('nlp', 'go'), ('welcome', 'lab')]\n"
          ]
        }
      ],
      "source": [
        "#Word Collocation\n",
        "finder = BigramCollocationFinder.from_words(filtered_words)\n",
        "top_collocations = finder.nbest(BigramAssocMeasures.likelihood_ratio, 5)\n",
        "\n",
        "print(\"Top 5 Word Collocations:\")\n",
        "print(top_collocations)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
